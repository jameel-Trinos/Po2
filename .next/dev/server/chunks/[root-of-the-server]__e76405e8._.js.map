{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 148, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/Trinos/Learning/PointofTwo/Po2/lib/pdfStorage.ts"],"sourcesContent":["/**\n * In-memory storage for PDF documents\n * Stores PDFs temporarily for conversion operations\n * \n * Note: This is a simple in-memory solution. For production,\n * consider using Redis, S3, or a database.\n */\n\ninterface StoredPDF {\n  buffer: Buffer;\n  fileName: string;\n  uploadedAt: Date;\n}\n\n// In-memory storage Map\nconst pdfStorage = new Map<string, StoredPDF>();\n\n// Cleanup interval (remove PDFs older than 24 hours)\nconst CLEANUP_INTERVAL = 60 * 60 * 1000; // 1 hour (check every hour)\nconst MAX_AGE = 24 * 60 * 60 * 1000; // 24 hours (keep PDFs for 24 hours)\n\n// Periodic cleanup\nif (typeof setInterval !== 'undefined') {\n  setInterval(() => {\n    const now = new Date();\n    for (const [id, pdf] of pdfStorage.entries()) {\n      const age = now.getTime() - pdf.uploadedAt.getTime();\n      if (age > MAX_AGE) {\n        console.log(`üóëÔ∏è  Cleaning up old PDF: ${id} (${pdf.fileName})`);\n        pdfStorage.delete(id);\n      }\n    }\n  }, CLEANUP_INTERVAL);\n}\n\n/**\n * Store a PDF in memory\n */\nexport function storePDF(documentId: string, buffer: Buffer, fileName: string): void {\n  console.log(`üíæ Storing PDF: ${documentId} (${fileName}, ${buffer.length} bytes)`);\n  pdfStorage.set(documentId, {\n    buffer,\n    fileName,\n    uploadedAt: new Date(),\n  });\n}\n\n/**\n * Retrieve a stored PDF\n */\nexport function getPDF(documentId: string): { buffer: Buffer; fileName: string } | null {\n  const stored = pdfStorage.get(documentId);\n  if (!stored) {\n    console.log(`‚ùå PDF not found: ${documentId}`);\n    return null;\n  }\n  console.log(`‚úÖ Retrieved PDF: ${documentId} (${stored.fileName}, ${stored.buffer.length} bytes)`);\n  return {\n    buffer: stored.buffer,\n    fileName: stored.fileName,\n  };\n}\n\n/**\n * Delete a stored PDF\n */\nexport function deletePDF(documentId: string): boolean {\n  const deleted = pdfStorage.delete(documentId);\n  if (deleted) {\n    console.log(`üóëÔ∏è  Deleted PDF: ${documentId}`);\n  }\n  return deleted;\n}\n\n/**\n * Get storage statistics\n */\nexport function getStorageStats(): { count: number; totalSize: number } {\n  let totalSize = 0;\n  for (const pdf of pdfStorage.values()) {\n    totalSize += pdf.buffer.length;\n  }\n  return {\n    count: pdfStorage.size,\n    totalSize,\n  };\n}\n\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;;;;;;;AAQD,wBAAwB;AACxB,MAAM,aAAa,IAAI;AAEvB,qDAAqD;AACrD,MAAM,mBAAmB,KAAK,KAAK,MAAM,4BAA4B;AACrE,MAAM,UAAU,KAAK,KAAK,KAAK,MAAM,oCAAoC;AAEzE,mBAAmB;AACnB,IAAI,OAAO,gBAAgB,aAAa;IACtC,YAAY;QACV,MAAM,MAAM,IAAI;QAChB,KAAK,MAAM,CAAC,IAAI,IAAI,IAAI,WAAW,OAAO,GAAI;YAC5C,MAAM,MAAM,IAAI,OAAO,KAAK,IAAI,UAAU,CAAC,OAAO;YAClD,IAAI,MAAM,SAAS;gBACjB,QAAQ,GAAG,CAAC,CAAC,0BAA0B,EAAE,GAAG,EAAE,EAAE,IAAI,QAAQ,CAAC,CAAC,CAAC;gBAC/D,WAAW,MAAM,CAAC;YACpB;QACF;IACF,GAAG;AACL;AAKO,SAAS,SAAS,UAAkB,EAAE,MAAc,EAAE,QAAgB;IAC3E,QAAQ,GAAG,CAAC,CAAC,gBAAgB,EAAE,WAAW,EAAE,EAAE,SAAS,EAAE,EAAE,OAAO,MAAM,CAAC,OAAO,CAAC;IACjF,WAAW,GAAG,CAAC,YAAY;QACzB;QACA;QACA,YAAY,IAAI;IAClB;AACF;AAKO,SAAS,OAAO,UAAkB;IACvC,MAAM,SAAS,WAAW,GAAG,CAAC;IAC9B,IAAI,CAAC,QAAQ;QACX,QAAQ,GAAG,CAAC,CAAC,iBAAiB,EAAE,YAAY;QAC5C,OAAO;IACT;IACA,QAAQ,GAAG,CAAC,CAAC,iBAAiB,EAAE,WAAW,EAAE,EAAE,OAAO,QAAQ,CAAC,EAAE,EAAE,OAAO,MAAM,CAAC,MAAM,CAAC,OAAO,CAAC;IAChG,OAAO;QACL,QAAQ,OAAO,MAAM;QACrB,UAAU,OAAO,QAAQ;IAC3B;AACF;AAKO,SAAS,UAAU,UAAkB;IAC1C,MAAM,UAAU,WAAW,MAAM,CAAC;IAClC,IAAI,SAAS;QACX,QAAQ,GAAG,CAAC,CAAC,kBAAkB,EAAE,YAAY;IAC/C;IACA,OAAO;AACT;AAKO,SAAS;IACd,IAAI,YAAY;IAChB,KAAK,MAAM,OAAO,WAAW,MAAM,GAAI;QACrC,aAAa,IAAI,MAAM,CAAC,MAAM;IAChC;IACA,OAAO;QACL,OAAO,WAAW,IAAI;QACtB;IACF;AACF","debugId":null}},
    {"offset": {"line": 229, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/Trinos/Learning/PointofTwo/Po2/lib/db.ts"],"sourcesContent":["import { PrismaClient } from \"@prisma/client\";\n\nconst globalForPrisma = globalThis as unknown as {\n  prisma: PrismaClient | undefined;\n};\n\nexport const prisma =\n  globalForPrisma.prisma ??\n  new PrismaClient({\n    log: process.env.NODE_ENV === \"development\" ? [\"query\", \"info\", \"warn\", \"error\"] : [\"error\"],\n  });\n\nif (process.env.NODE_ENV !== \"production\") globalForPrisma.prisma = prisma;\n\n"],"names":[],"mappings":";;;;AAAA;;AAEA,MAAM,kBAAkB;AAIjB,MAAM,SACX,gBAAgB,MAAM,IACtB,IAAI,6IAAY,CAAC;IACf,KAAK,uCAAyC;QAAC;QAAS;QAAQ;QAAQ;KAAQ,GAAG;AACrF;AAEF,wCAA2C,gBAAgB,MAAM,GAAG","debugId":null}},
    {"offset": {"line": 249, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/Trinos/Learning/PointofTwo/Po2/lib/db-helpers.ts"],"sourcesContent":["import { prisma } from \"./db\";\nimport type { Prisma } from \"@prisma/client\";\n\n/**\n * Save an uploaded document to the database\n * @param userId - Clerk user ID (string)\n * @param originalName - Original filename\n * @param fileType - File type (e.g., \"pdf\", \"docx\")\n * @param storageUrl - URL or path where the file is stored\n * @returns The created document\n */\nexport async function saveUploadedDocument(\n  userId: string,\n  originalName: string,\n  fileType: string,\n  storageUrl: string\n) {\n  try {\n    const document = await prisma.document.create({\n      data: {\n        userId,\n        originalName,\n        fileType,\n        storageUrl,\n      },\n    });\n    return document;\n  } catch (error) {\n    console.error(\"Error saving document:\", error);\n    throw new Error(\"Failed to save document to database\");\n  }\n}\n\n/**\n * Save AI-generated suggestions for a document\n * @param documentId - Document ID\n * @param suggestions - Array of suggestion objects\n * @returns Array of created suggestions\n */\nexport async function saveAISuggestions(\n  documentId: string,\n  suggestions: Array<{\n    category: string;\n    issue: string;\n    severity: string;\n    startIndex?: number | null;\n    endIndex?: number | null;\n    suggestedFix?: string | null;\n  }>\n) {\n  try {\n    // Delete existing suggestions for this document (optional - you might want to keep them)\n    // await prisma.suggestion.deleteMany({ where: { documentId } });\n\n    // Create new suggestions\n    const createdSuggestions = await prisma.suggestion.createMany({\n      data: suggestions.map((s) => ({\n        documentId,\n        category: s.category,\n        issue: s.issue,\n        severity: s.severity,\n        startIndex: s.startIndex ?? null,\n        endIndex: s.endIndex ?? null,\n        suggestedFix: s.suggestedFix ?? null,\n      })),\n      skipDuplicates: true,\n    });\n\n    // Fetch and return the created suggestions\n    const savedSuggestions = await prisma.suggestion.findMany({\n      where: { documentId },\n      orderBy: { id: \"asc\" },\n    });\n\n    return savedSuggestions;\n  } catch (error) {\n    console.error(\"Error saving suggestions:\", error);\n    throw new Error(\"Failed to save suggestions to database\");\n  }\n}\n\n/**\n * Get a document with all its suggestions\n * @param documentId - Document ID\n * @param userId - Optional user ID for security check\n * @returns Document with suggestions, or null if not found\n */\nexport async function getDocumentWithSuggestions(\n  documentId: string,\n  userId?: string\n) {\n  try {\n    const where: Prisma.DocumentWhereInput = { id: documentId };\n    if (userId) {\n      where.userId = userId;\n    }\n\n    const document = await prisma.document.findFirst({\n      where,\n      include: {\n        suggestions: {\n          orderBy: [\n            { severity: \"asc\" }, // Critical first\n            { category: \"asc\" },\n          ],\n        },\n      },\n    });\n\n    return document;\n  } catch (error) {\n    console.error(\"Error fetching document:\", error);\n    throw new Error(\"Failed to fetch document from database\");\n  }\n}\n\n/**\n * Get all documents for a user\n * @param userId - Clerk user ID\n * @returns Array of documents with suggestion counts\n */\nexport async function getUserDocuments(userId: string) {\n  try {\n    const documents = await prisma.document.findMany({\n      where: { userId },\n      include: {\n        _count: {\n          select: { suggestions: true },\n        },\n      },\n      orderBy: { createdAt: \"desc\" },\n    });\n\n    return documents;\n  } catch (error) {\n    console.error(\"Error fetching user documents:\", error);\n    \n    // Provide more specific error messages\n    if (error instanceof Error) {\n      // Check for common Prisma errors\n      if (error.message.includes('P1001') || error.message.includes('Can\\'t reach database server')) {\n        throw new Error(\"Database connection failed. Please check your DATABASE_URL environment variable.\");\n      }\n      if (error.message.includes('P2002')) {\n        throw new Error(\"Database constraint violation\");\n      }\n      if (error.message.includes('P2025')) {\n        throw new Error(\"Record not found\");\n      }\n      // Re-throw with original message for other errors\n      throw new Error(`Failed to fetch user documents: ${error.message}`);\n    }\n    \n    throw new Error(\"Failed to fetch user documents: Unknown error\");\n  }\n}\n\n/**\n * Update a document\n * @param documentId - Document ID\n * @param userId - User ID for security check\n * @param data - Partial document data to update\n * @returns Updated document\n */\nexport async function updateDocument(\n  documentId: string,\n  userId: string,\n  data: Partial<{\n    originalName: string;\n    fileType: string;\n    storageUrl: string;\n  }>\n) {\n  try {\n    const document = await prisma.document.updateMany({\n      where: {\n        id: documentId,\n        userId, // Ensure user owns the document\n      },\n      data,\n    });\n\n    if (document.count === 0) {\n      throw new Error(\"Document not found or access denied\");\n    }\n\n    return await prisma.document.findUnique({\n      where: { id: documentId },\n    });\n  } catch (error) {\n    console.error(\"Error updating document:\", error);\n    throw new Error(\"Failed to update document\");\n  }\n}\n\n/**\n * Delete a document and its suggestions (cascade)\n * @param documentId - Document ID\n * @param userId - User ID for security check\n */\nexport async function deleteDocument(documentId: string, userId: string) {\n  try {\n    const result = await prisma.document.deleteMany({\n      where: {\n        id: documentId,\n        userId, // Ensure user owns the document\n      },\n    });\n\n    if (result.count === 0) {\n      throw new Error(\"Document not found or access denied\");\n    }\n\n    return { success: true };\n  } catch (error) {\n    console.error(\"Error deleting document:\", error);\n    throw new Error(\"Failed to delete document\");\n  }\n}\n\n/**\n * Update a suggestion\n * @param suggestionId - Suggestion ID\n * @param data - Partial suggestion data to update\n * @param documentId - Optional document ID to verify the suggestion belongs to the document\n * @returns Updated suggestion\n */\nexport async function updateSuggestion(\n  suggestionId: string,\n  data: Partial<{\n    category: string;\n    issue: string;\n    severity: string;\n    startIndex: number | null;\n    endIndex: number | null;\n    suggestedFix: string | null;\n  }>,\n  documentId?: string\n) {\n  try {\n    // First, check if the suggestion exists\n    const existingSuggestion = await prisma.suggestion.findUnique({\n      where: { id: suggestionId },\n    });\n\n    if (!existingSuggestion) {\n      throw new Error(`Suggestion with ID ${suggestionId} not found`);\n    }\n\n    // If documentId is provided, verify the suggestion belongs to that document\n    if (documentId && existingSuggestion.documentId !== documentId) {\n      throw new Error(\"Suggestion does not belong to the specified document\");\n    }\n\n    // Update the suggestion\n    const suggestion = await prisma.suggestion.update({\n      where: { id: suggestionId },\n      data,\n    });\n\n    return suggestion;\n  } catch (error) {\n    console.error(\"Error updating suggestion:\", error);\n    \n    // Handle Prisma P2025 error (record not found)\n    if (error && typeof error === 'object' && 'code' in error && error.code === 'P2025') {\n      throw new Error(`Suggestion with ID ${suggestionId} not found`);\n    }\n    \n    // Re-throw if it's already our custom error\n    if (error instanceof Error) {\n      throw error;\n    }\n    \n    throw new Error(\"Failed to update suggestion\");\n  }\n}\n\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;;AAWO,eAAe,qBACpB,MAAc,EACd,YAAoB,EACpB,QAAgB,EAChB,UAAkB;IAElB,IAAI;QACF,MAAM,WAAW,MAAM,qHAAM,CAAC,QAAQ,CAAC,MAAM,CAAC;YAC5C,MAAM;gBACJ;gBACA;gBACA;gBACA;YACF;QACF;QACA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0BAA0B;QACxC,MAAM,IAAI,MAAM;IAClB;AACF;AAQO,eAAe,kBACpB,UAAkB,EAClB,WAOE;IAEF,IAAI;QACF,yFAAyF;QACzF,iEAAiE;QAEjE,yBAAyB;QACzB,MAAM,qBAAqB,MAAM,qHAAM,CAAC,UAAU,CAAC,UAAU,CAAC;YAC5D,MAAM,YAAY,GAAG,CAAC,CAAC,IAAM,CAAC;oBAC5B;oBACA,UAAU,EAAE,QAAQ;oBACpB,OAAO,EAAE,KAAK;oBACd,UAAU,EAAE,QAAQ;oBACpB,YAAY,EAAE,UAAU,IAAI;oBAC5B,UAAU,EAAE,QAAQ,IAAI;oBACxB,cAAc,EAAE,YAAY,IAAI;gBAClC,CAAC;YACD,gBAAgB;QAClB;QAEA,2CAA2C;QAC3C,MAAM,mBAAmB,MAAM,qHAAM,CAAC,UAAU,CAAC,QAAQ,CAAC;YACxD,OAAO;gBAAE;YAAW;YACpB,SAAS;gBAAE,IAAI;YAAM;QACvB;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,6BAA6B;QAC3C,MAAM,IAAI,MAAM;IAClB;AACF;AAQO,eAAe,2BACpB,UAAkB,EAClB,MAAe;IAEf,IAAI;QACF,MAAM,QAAmC;YAAE,IAAI;QAAW;QAC1D,IAAI,QAAQ;YACV,MAAM,MAAM,GAAG;QACjB;QAEA,MAAM,WAAW,MAAM,qHAAM,CAAC,QAAQ,CAAC,SAAS,CAAC;YAC/C;YACA,SAAS;gBACP,aAAa;oBACX,SAAS;wBACP;4BAAE,UAAU;wBAAM;wBAClB;4BAAE,UAAU;wBAAM;qBACnB;gBACH;YACF;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,4BAA4B;QAC1C,MAAM,IAAI,MAAM;IAClB;AACF;AAOO,eAAe,iBAAiB,MAAc;IACnD,IAAI;QACF,MAAM,YAAY,MAAM,qHAAM,CAAC,QAAQ,CAAC,QAAQ,CAAC;YAC/C,OAAO;gBAAE;YAAO;YAChB,SAAS;gBACP,QAAQ;oBACN,QAAQ;wBAAE,aAAa;oBAAK;gBAC9B;YACF;YACA,SAAS;gBAAE,WAAW;YAAO;QAC/B;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAEhD,uCAAuC;QACvC,IAAI,iBAAiB,OAAO;YAC1B,iCAAiC;YACjC,IAAI,MAAM,OAAO,CAAC,QAAQ,CAAC,YAAY,MAAM,OAAO,CAAC,QAAQ,CAAC,iCAAiC;gBAC7F,MAAM,IAAI,MAAM;YAClB;YACA,IAAI,MAAM,OAAO,CAAC,QAAQ,CAAC,UAAU;gBACnC,MAAM,IAAI,MAAM;YAClB;YACA,IAAI,MAAM,OAAO,CAAC,QAAQ,CAAC,UAAU;gBACnC,MAAM,IAAI,MAAM;YAClB;YACA,kDAAkD;YAClD,MAAM,IAAI,MAAM,CAAC,gCAAgC,EAAE,MAAM,OAAO,EAAE;QACpE;QAEA,MAAM,IAAI,MAAM;IAClB;AACF;AASO,eAAe,eACpB,UAAkB,EAClB,MAAc,EACd,IAIE;IAEF,IAAI;QACF,MAAM,WAAW,MAAM,qHAAM,CAAC,QAAQ,CAAC,UAAU,CAAC;YAChD,OAAO;gBACL,IAAI;gBACJ;YACF;YACA;QACF;QAEA,IAAI,SAAS,KAAK,KAAK,GAAG;YACxB,MAAM,IAAI,MAAM;QAClB;QAEA,OAAO,MAAM,qHAAM,CAAC,QAAQ,CAAC,UAAU,CAAC;YACtC,OAAO;gBAAE,IAAI;YAAW;QAC1B;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,4BAA4B;QAC1C,MAAM,IAAI,MAAM;IAClB;AACF;AAOO,eAAe,eAAe,UAAkB,EAAE,MAAc;IACrE,IAAI;QACF,MAAM,SAAS,MAAM,qHAAM,CAAC,QAAQ,CAAC,UAAU,CAAC;YAC9C,OAAO;gBACL,IAAI;gBACJ;YACF;QACF;QAEA,IAAI,OAAO,KAAK,KAAK,GAAG;YACtB,MAAM,IAAI,MAAM;QAClB;QAEA,OAAO;YAAE,SAAS;QAAK;IACzB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,4BAA4B;QAC1C,MAAM,IAAI,MAAM;IAClB;AACF;AASO,eAAe,iBACpB,YAAoB,EACpB,IAOE,EACF,UAAmB;IAEnB,IAAI;QACF,wCAAwC;QACxC,MAAM,qBAAqB,MAAM,qHAAM,CAAC,UAAU,CAAC,UAAU,CAAC;YAC5D,OAAO;gBAAE,IAAI;YAAa;QAC5B;QAEA,IAAI,CAAC,oBAAoB;YACvB,MAAM,IAAI,MAAM,CAAC,mBAAmB,EAAE,aAAa,UAAU,CAAC;QAChE;QAEA,4EAA4E;QAC5E,IAAI,cAAc,mBAAmB,UAAU,KAAK,YAAY;YAC9D,MAAM,IAAI,MAAM;QAClB;QAEA,wBAAwB;QACxB,MAAM,aAAa,MAAM,qHAAM,CAAC,UAAU,CAAC,MAAM,CAAC;YAChD,OAAO;gBAAE,IAAI;YAAa;YAC1B;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,8BAA8B;QAE5C,+CAA+C;QAC/C,IAAI,SAAS,OAAO,UAAU,YAAY,UAAU,SAAS,MAAM,IAAI,KAAK,SAAS;YACnF,MAAM,IAAI,MAAM,CAAC,mBAAmB,EAAE,aAAa,UAAU,CAAC;QAChE;QAEA,4CAA4C;QAC5C,IAAI,iBAAiB,OAAO;YAC1B,MAAM;QACR;QAEA,MAAM,IAAI,MAAM;IAClB;AACF","debugId":null}},
    {"offset": {"line": 463, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/Trinos/Learning/PointofTwo/Po2/app/api/compliance/analyze/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\nimport { auth } from '@clerk/nextjs/server';\nimport mammoth from 'mammoth';\nimport PDFParser from 'pdf2json';\nimport { storePDF } from '@/lib/pdfStorage';\nimport { saveUploadedDocument, saveAISuggestions } from '@/lib/db-helpers';\n\n// Force Node.js runtime for mammoth compatibility\nexport const runtime = 'nodejs';\n\n// Helper function to create properly formatted error responses\nfunction createErrorResponse(error: string, details: string, status: number = 500) {\n  const errorResponse = {\n    error,\n    details,\n    timestamp: new Date().toISOString()\n  };\n  \n  console.error('üì§ Creating error response:', JSON.stringify(errorResponse, null, 2));\n  \n  return NextResponse.json(errorResponse, { \n    status,\n    headers: {\n      'Content-Type': 'application/json',\n      'Cache-Control': 'no-cache, no-store, must-revalidate'\n    }\n  });\n}\n\n// Mock compliance issues generator\nfunction generateMockCompliance(text: string) {\n  const suggestions: Array<{\n    category: string;\n    severity: string;\n    originalText: string;\n    suggestedText: string;\n    explanation: string;\n    page: number;\n  }> = [];\n  \n  // Clean up text: normalize whitespace and preserve original casing for display\n  const normalizedText = text.replace(/\\s+/g, ' ').trim();\n  \n  // FINRA compliance suggestions\n  const finraPatterns = [\n    {\n      pattern: /\\b(guaranteed?|guarantees?)\\s+(returns?|profits?|income|gains?)\\b/gi,\n      category: 'FINRA',\n      severity: 'critical',\n      explanation: 'FINRA Rule 2210 prohibits guarantees of investment returns',\n      getReplacement: (match: string) => match.replace(/guaranteed?|guarantees?/gi, 'potential')\n    },\n    {\n      pattern: /\\b(promise|promises|assure|assures)\\s+(returns?|profits?|income|gains?)\\b/gi,\n      category: 'FINRA',\n      severity: 'critical',\n      explanation: 'FINRA Rule 2210 prohibits promises of specific investment returns',\n      getReplacement: (match: string) => match.replace(/promise|promises|assure|assures/gi, 'target')\n    },\n    {\n      pattern: /\\bhigh returns?\\b/gi,\n      category: 'FINRA',\n      severity: 'critical',\n      explanation: 'Claims of \"high returns\" may violate FINRA communications standards',\n      getReplacement: (match: string) => 'competitive returns'\n    },\n    {\n      pattern: /\\brisk[- ]free\\b/gi,\n      category: 'FINRA',\n      severity: 'critical',\n      explanation: 'No investment is truly risk-free. This violates FINRA Rule 2210',\n      getReplacement: (match: string) => 'lower-risk'\n    },\n    {\n      pattern: /\\b(best|top|#1|number one)\\s+(investment|fund|stock|opportunity)\\b/gi,\n      category: 'FINRA',\n      severity: 'warning',\n      explanation: 'Superlative claims require substantiation per FINRA Rule 2210',\n      getReplacement: (match: string) => match.replace(/best|top|#1|number one/gi, 'leading')\n    },\n    {\n      pattern: /\\bno risk\\b/gi,\n      category: 'FINRA',\n      severity: 'critical',\n      explanation: 'All investments carry some level of risk per FINRA requirements',\n      getReplacement: (match: string) => 'minimal risk'\n    },\n    {\n      pattern: /\\bsafe investment\\b/gi,\n      category: 'FINRA',\n      severity: 'warning',\n      explanation: 'The term \"safe\" may be misleading per FINRA standards',\n      getReplacement: (match: string) => 'conservative investment'\n    },\n    {\n      pattern: /\\b(can'?t|cannot|won'?t)\\s+(lose|fail)\\b/gi,\n      category: 'FINRA',\n      severity: 'critical',\n      explanation: 'Statements implying no possibility of loss violate FINRA Rule 2210',\n      getReplacement: (match: string) => 'historically resilient'\n    }\n  ];\n\n  // SEC compliance suggestions\n  const secPatterns = [\n    {\n      pattern: /\\binsider (information|knowledge|tip|trading)\\b/gi,\n      category: 'SEC',\n      severity: 'critical',\n      explanation: 'Reference to insider information may violate SEC Rule 10b-5',\n      getReplacement: (match: string) => 'publicly available information'\n    },\n    {\n      pattern: /\\bconfidential (deal|agreement|information|data)\\b/gi,\n      category: 'SEC',\n      severity: 'warning',\n      explanation: 'Disclosure of confidential information may violate SEC regulations',\n      getReplacement: (match: string) => match.replace(/confidential/gi, 'publicly disclosed')\n    },\n    {\n      pattern: /\\b(manipulation|manipulate|manipulating)\\s+(price|market|stock)\\b/gi,\n      category: 'SEC',\n      severity: 'critical',\n      explanation: 'References to market manipulation should be avoided or clarified',\n      getReplacement: (match: string) => 'market activity'\n    },\n    {\n      pattern: /\\bunregistered (security|securities|offering)\\b/gi,\n      category: 'SEC',\n      severity: 'critical',\n      explanation: 'Unregistered securities must comply with SEC regulations',\n      getReplacement: (match: string) => 'private placement'\n    }\n  ];\n\n  // Grammar suggestions\n  const grammarPatterns = [\n    {\n      pattern: /\\btheir\\s+are\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect usage: \"their\" should be \"there\"',\n      getReplacement: (match: string) => 'there are'\n    },\n    {\n      pattern: /\\btheir\\s+(is|was|were)\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect usage: \"their\" should be \"there\"',\n      getReplacement: (match: string) => match.replace(/their/gi, 'there')\n    },\n    {\n      pattern: /\\byour\\s+welcome\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect usage: \"your\" should be \"you\\'re\" (you are)',\n      getReplacement: (match: string) => \"you're welcome\"\n    },\n    {\n      pattern: /\\bits\\s+(a|the|an)\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect usage: \"its\" should be \"it\\'s\" (it is)',\n      getReplacement: (match: string) => match.replace(/its/gi, \"it's\")\n    },\n    {\n      pattern: /\\beffect\\s+(change|growth|improvement)\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Should use \"affect\" (verb) not \"effect\" (noun) in this context',\n      getReplacement: (match: string) => match.replace(/effect/gi, 'affect')\n    },\n    {\n      pattern: /\\balot\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect spelling: should be \"a lot\" (two words)',\n      getReplacement: (match: string) => 'a lot'\n    },\n    {\n      pattern: /\\bcould\\s+of\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect usage: should be \"could have\" or \"could\\'ve\"',\n      getReplacement: (match: string) => 'could have'\n    },\n    {\n      pattern: /\\bshould\\s+of\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect usage: should be \"should have\" or \"should\\'ve\"',\n      getReplacement: (match: string) => 'should have'\n    },\n    {\n      pattern: /\\bwould\\s+of\\b/gi,\n      category: 'Grammar',\n      severity: 'info',\n      explanation: 'Incorrect usage: should be \"would have\" or \"would\\'ve\"',\n      getReplacement: (match: string) => 'would have'\n    }\n  ];\n\n  const allPatterns = [...finraPatterns, ...secPatterns, ...grammarPatterns];\n\n  // Find matches in text - use both original and normalized text\n  allPatterns.forEach((pattern) => {\n    const matches = Array.from(text.matchAll(pattern.pattern));\n    \n    console.log(`  Pattern \"${pattern.pattern}\" found ${matches.length} matches`);\n    \n    for (const match of matches) {\n      if (match[0]) {\n        // Get the suggested replacement text\n        const suggestedText = pattern.getReplacement(match[0]);\n        \n        // Get context around the match (50 chars before and after)\n        const matchIndex = match.index || 0;\n        const contextStart = Math.max(0, matchIndex - 50);\n        const contextEnd = Math.min(text.length, matchIndex + match[0].length + 50);\n        const context = text.substring(contextStart, contextEnd);\n        \n        console.log(`    Match: \"${match[0]}\" ‚Üí \"${suggestedText}\"`);\n        console.log(`    Context: ...${context}...`);\n        \n        suggestions.push({\n          category: pattern.category,\n          severity: pattern.severity,\n          originalText: match[0],\n          suggestedText: suggestedText,\n          explanation: pattern.explanation,\n          page: 1,\n        });\n      }\n    }\n  });\n\n  return suggestions;\n}\n\nexport async function POST(request: NextRequest) {\n  console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');\n  console.log('üöÄ POST /api/compliance/analyze called');\n  console.log('  Timestamp:', new Date().toISOString());\n  console.log('  URL:', request.url);\n  console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');\n  \n  try {\n    // Get authenticated user\n    // In Clerk v6, auth() automatically reads from the request\n    const { userId } = await auth();\n    \n    if (!userId) {\n      console.error('‚ùå No userId found. Auth check failed.');\n      console.error('  Request URL:', request.url);\n      console.error('  Request headers:', {\n        cookie: request.headers.get('cookie') ? 'present (length: ' + request.headers.get('cookie')?.length + ')' : 'missing',\n        'user-agent': request.headers.get('user-agent')?.substring(0, 50) || 'missing',\n      });\n      return createErrorResponse(\n        'Unauthorized',\n        'You must be signed in to upload documents. Please refresh the page and try again.',\n        401\n      );\n    }\n    \n    console.log('‚úÖ User authenticated:', userId);\n    console.log('üìã Request details:');\n    console.log('  Method:', request.method);\n    console.log('  Content-Type:', request.headers.get('content-type'));\n    \n    // Wrap formData parsing in try-catch to handle parsing errors\n    let formData;\n    try {\n      formData = await request.formData();\n    } catch (parseError) {\n      console.error('‚ùå Failed to parse form data:', parseError);\n      return createErrorResponse(\n        'Invalid request format',\n        'Failed to parse form data. Please ensure you are sending a valid multipart/form-data request.',\n        400\n      );\n    }\n    console.log('‚úÖ FormData parsed successfully');\n    const file = formData.get('file') as File;\n\n    if (!file) {\n      console.error('‚ùå No file provided in form data');\n      return createErrorResponse(\n        'No file provided',\n        'The file field is missing from the form data',\n        400\n      );\n    }\n\n    console.log('‚úÖ File received:', {\n      name: file.name,\n      size: file.size,\n      type: file.type\n    });\n\n    // Validate file type\n    const fileName = file.name.toLowerCase();\n    const isPdf = fileName.endsWith('.pdf') || file.type === 'application/pdf';\n    const isDocx = fileName.endsWith('.docx') || file.type.includes('officedocument.wordprocessingml');\n    const isPlainText = fileName.endsWith('.txt') || file.type === 'text/plain' || formData.get('isPlainText') === 'true';\n\n    if (!isPdf && !isDocx && !isPlainText) {\n      console.error('‚ùå Invalid file type:', fileName, 'Type:', file.type);\n      return createErrorResponse(\n        'Invalid file type',\n        `Only .pdf, .docx, and .txt files are supported. Received: ${fileName} (${file.type})`,\n        400\n      );\n    }\n\n    // Extract text from file\n    console.log('Converting file to array buffer...');\n    let arrayBuffer;\n    try {\n      arrayBuffer = await file.arrayBuffer();\n      console.log('Array buffer size:', arrayBuffer.byteLength);\n    } catch (bufferError) {\n      console.error('‚ùå Failed to read file:', bufferError);\n      return createErrorResponse(\n        'File read error',\n        'Failed to read the uploaded file. The file may be corrupted or too large.',\n        400\n      );\n    }\n    \n    let extractedText: string;\n    let htmlContent: string;\n    let fileType: 'pdf' | 'docx';\n    let pdfUrl: string | undefined;\n    \n    // Generate document ID early (before processing) so we can use it for PDF storage\n    const documentId = Date.now().toString();\n    \n    // Declare buffer at function scope to avoid duplicate declarations\n    let buffer: Buffer;\n\n    if (isPdf) {\n      fileType = 'pdf';\n      console.log('Processing PDF file...');\n      \n      try {\n        // Convert ArrayBuffer to Buffer for pdf2json\n        buffer = Buffer.from(arrayBuffer);\n        \n        // Extract text using pdf2json with page information\n        const { text: extractedTextResult, pageTexts } = await new Promise<{ text: string; pageTexts: string[] }>((resolve, reject) => {\n          // Create PDFParser without the problematic second parameter\n          const pdfParser = new (PDFParser as any)();\n          \n          pdfParser.on('pdfParser_dataError', (errData: any) => {\n            console.error('PDF parse error:', errData.parserError);\n            reject(new Error(errData.parserError || 'Failed to parse PDF'));\n          });\n          \n          pdfParser.on('pdfParser_dataReady', (pdfData: any) => {\n            try {\n              // Extract text from all pages\n              const fullText = (pdfParser as any).getRawTextContent();\n              \n              // Try to extract per-page text if available\n              const pageTexts: string[] = [];\n              if (pdfData?.Pages && Array.isArray(pdfData.Pages)) {\n                console.log(`üìÑ PDF has ${pdfData.Pages.length} pages`);\n                pdfData.Pages.forEach((page: any, index: number) => {\n                  let pageText = '';\n                  if (page.Texts && Array.isArray(page.Texts)) {\n                    pageText = page.Texts.map((text: any) => {\n                      const encodedText = text.R?.[0]?.T || '';\n                      try {\n                        // Try to decode URI component, but fall back to raw text if it fails\n                        return decodeURIComponent(encodedText);\n                      } catch (decodeError) {\n                        // If decoding fails (malformed URI), return the raw text\n                        console.warn(`‚ö†Ô∏è Failed to decode text: \"${encodedText}\". Using raw text.`);\n                        return encodedText;\n                      }\n                    }).join(' ');\n                  }\n                  pageTexts.push(pageText);\n                  console.log(`  Page ${index + 1}: ${pageText.length} chars`);\n                });\n              }\n              \n              console.log('‚úÖ PDF text extracted successfully');\n              console.log('üìÑ First 200 chars:', fullText.substring(0, 200));\n              resolve({ text: fullText, pageTexts });\n            } catch (err) {\n              console.error('Error extracting text:', err);\n              reject(err);\n            }\n          });\n          \n          // Parse the buffer\n          pdfParser.parseBuffer(buffer);\n        });\n        \n        extractedText = extractedTextResult;\n        \n        console.log('Extracted text length:', extractedText.length);\n        console.log('Extracted text preview:', extractedText.substring(0, 500));\n\n        // Convert extracted text to basic HTML for editor\n        htmlContent = extractedText\n          .split('\\n\\n')\n          .filter(p => p.trim())\n          .map(p => `<p>${p.trim().replace(/\\n/g, '<br>')}</p>`)\n          .join('\\n');\n        \n        // Store the PDF buffer in memory for later conversion\n        // (buffer was already created at line 323)\n        storePDF(documentId, buffer, file.name);\n        \n        // Create a blob URL for the PDF (base64 encoded) for viewing\n        const base64 = buffer.toString('base64');\n        pdfUrl = `data:application/pdf;base64,${base64}`;\n      } catch (pdfError) {\n        console.error('‚ùå PDF processing failed:', pdfError);\n        return createErrorResponse(\n          'PDF processing error',\n          pdfError instanceof Error ? pdfError.message : 'Failed to process PDF file. The file may be corrupted or use an unsupported format.',\n          400\n        );\n      }\n      \n    } else if (isPlainText) {\n      fileType = 'docx'; // Treat plain text as editable content (same as DOCX)\n      console.log('Processing plain text file...');\n      \n      try {\n        // Read plain text directly\n        const textDecoder = new TextDecoder('utf-8');\n        extractedText = textDecoder.decode(arrayBuffer);\n        console.log('Extracted text length:', extractedText.length);\n        console.log('Extracted text preview:', extractedText.substring(0, 500));\n\n        // Convert plain text to HTML for editor\n        htmlContent = extractedText\n          .split('\\n')\n          .filter(p => p.trim())\n          .map(p => `<p>${p.trim()}</p>`)\n          .join('\\n');\n        console.log('HTML content length:', htmlContent.length);\n      } catch (textError) {\n        console.error('‚ùå Text processing failed:', textError);\n        return createErrorResponse(\n          'Text processing error',\n          textError instanceof Error ? textError.message : 'Failed to process text file.',\n          400\n        );\n      }\n      \n    } else {\n      fileType = 'docx';\n      console.log('Processing DOCX file...');\n      \n      try {\n        // Convert ArrayBuffer to Buffer for mammoth\n        buffer = Buffer.from(arrayBuffer);\n        console.log('Buffer size:', buffer.length);\n        \n        console.log('Extracting raw text with mammoth...');\n        const result = await mammoth.extractRawText({ buffer });\n        extractedText = result.value;\n        console.log('Extracted text length:', extractedText.length);\n\n        // Also convert to HTML for editor\n        console.log('Converting to HTML with mammoth...');\n        const htmlResult = await mammoth.convertToHtml({ buffer });\n        htmlContent = htmlResult.value;\n        console.log('HTML content length:', htmlContent.length);\n      } catch (docxError) {\n        console.error('‚ùå DOCX processing failed:', docxError);\n        return createErrorResponse(\n          'DOCX processing error',\n          docxError instanceof Error ? docxError.message : 'Failed to process DOCX file. The file may be corrupted or use an unsupported format.',\n          400\n        );\n      }\n    }\n\n    // Generate mock compliance suggestions\n    console.log('üîç Analyzing text for compliance issues...');\n    const suggestions = generateMockCompliance(extractedText);\n    console.log(`‚úÖ Found ${suggestions.length} compliance suggestions`);\n    \n    if (suggestions.length > 0) {\n      console.log('Sample suggestion:', suggestions[0]);\n    } else {\n      console.log('‚ö†Ô∏è No compliance issues detected. Sample text:', extractedText.substring(0, 200));\n    }\n\n    // Save document to database\n    console.log('üíæ Saving document to database...');\n    let savedDocument;\n    try {\n      // Use a storage URL - for now, we'll use the documentId as a reference\n      // In production, you'd upload the file to S3/storage and use that URL\n      const storageUrl = `local://${documentId}`;\n      \n      savedDocument = await saveUploadedDocument(\n        userId,\n        file.name,\n        fileType,\n        storageUrl\n      );\n      \n      console.log('‚úÖ Document saved to database:', savedDocument.id);\n      \n      // Save suggestions to database\n      if (suggestions.length > 0) {\n        console.log('üíæ Saving suggestions to database...');\n        const dbSuggestions = suggestions.map(s => ({\n          category: s.category,\n          issue: s.explanation,\n          severity: s.severity,\n          startIndex: null, // Could calculate from text position if needed\n          endIndex: null,\n          suggestedFix: s.suggestedText,\n        }));\n        \n        await saveAISuggestions(savedDocument.id, dbSuggestions);\n        console.log(`‚úÖ Saved ${suggestions.length} suggestions to database`);\n      }\n    } catch (dbError) {\n      console.error('‚ùå Database error:', dbError);\n      // Continue with response even if database save fails\n      // In production, you might want to handle this differently\n    }\n\n    // Mock: Deduct balance for API usage (0.10 credits per analysis)\n    const costPerAnalysis = 0.10;\n\n    const successResponse = {\n      success: true,\n      documentId: savedDocument?.id || documentId, // Use database ID if available\n      fileName: file.name,\n      fileType,\n      htmlContent,\n      extractedText,\n      suggestions,\n      pdfUrl, // Only present for PDF files (as data URL for viewing)\n      cost: costPerAnalysis,\n      message: `Analysis complete. Found ${suggestions.length} suggestions.`,\n    };\n    \n    console.log('‚úÖ Returning success response');\n    console.log('  Document ID:', successResponse.documentId);\n    console.log('  File type:', successResponse.fileType);\n    console.log('  Suggestions count:', successResponse.suggestions.length);\n    \n    return NextResponse.json(successResponse);\n  } catch (error) {\n    console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');\n    console.error('‚ùå ERROR in /api/compliance/analyze');\n    console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');\n    console.error('Error type:', error?.constructor?.name || typeof error);\n    console.error('Error message:', error instanceof Error ? error.message : String(error));\n    console.error('Error stack:', error instanceof Error ? error.stack : 'No stack trace');\n    console.error('Full error object:', JSON.stringify(error, Object.getOwnPropertyNames(error), 2));\n    \n    const errorMessage = error instanceof Error ? error.message : String(error);\n    const errorResponse = createErrorResponse(\n      'Failed to analyze document',\n      errorMessage || 'An unexpected error occurred during document analysis',\n      500\n    );\n    \n    // Final safety check: ensure the response has a body\n    console.log('üì§ Returning error response with status:', errorResponse.status);\n    \n    return errorResponse;\n  }\n}\n\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;AAGO,MAAM,UAAU;AAEvB,+DAA+D;AAC/D,SAAS,oBAAoB,KAAa,EAAE,OAAe,EAAE,SAAiB,GAAG;IAC/E,MAAM,gBAAgB;QACpB;QACA;QACA,WAAW,IAAI,OAAO,WAAW;IACnC;IAEA,QAAQ,KAAK,CAAC,+BAA+B,KAAK,SAAS,CAAC,eAAe,MAAM;IAEjF,OAAO,gJAAY,CAAC,IAAI,CAAC,eAAe;QACtC;QACA,SAAS;YACP,gBAAgB;YAChB,iBAAiB;QACnB;IACF;AACF;AAEA,mCAAmC;AACnC,SAAS,uBAAuB,IAAY;IAC1C,MAAM,cAOD,EAAE;IAEP,+EAA+E;IAC/E,MAAM,iBAAiB,KAAK,OAAO,CAAC,QAAQ,KAAK,IAAI;IAErD,+BAA+B;IAC/B,MAAM,gBAAgB;QACpB;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB,MAAM,OAAO,CAAC,6BAA6B;QAChF;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB,MAAM,OAAO,CAAC,qCAAqC;QACxF;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB,MAAM,OAAO,CAAC,4BAA4B;QAC/E;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;KACD;IAED,6BAA6B;IAC7B,MAAM,cAAc;QAClB;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB,MAAM,OAAO,CAAC,kBAAkB;QACrE;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;KACD;IAED,sBAAsB;IACtB,MAAM,kBAAkB;QACtB;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB,MAAM,OAAO,CAAC,WAAW;QAC9D;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB,MAAM,OAAO,CAAC,SAAS;QAC5D;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB,MAAM,OAAO,CAAC,YAAY;QAC/D;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;QACA;YACE,SAAS;YACT,UAAU;YACV,UAAU;YACV,aAAa;YACb,gBAAgB,CAAC,QAAkB;QACrC;KACD;IAED,MAAM,cAAc;WAAI;WAAkB;WAAgB;KAAgB;IAE1E,+DAA+D;IAC/D,YAAY,OAAO,CAAC,CAAC;QACnB,MAAM,UAAU,MAAM,IAAI,CAAC,KAAK,QAAQ,CAAC,QAAQ,OAAO;QAExD,QAAQ,GAAG,CAAC,CAAC,WAAW,EAAE,QAAQ,OAAO,CAAC,QAAQ,EAAE,QAAQ,MAAM,CAAC,QAAQ,CAAC;QAE5E,KAAK,MAAM,SAAS,QAAS;YAC3B,IAAI,KAAK,CAAC,EAAE,EAAE;gBACZ,qCAAqC;gBACrC,MAAM,gBAAgB,QAAQ,cAAc,CAAC,KAAK,CAAC,EAAE;gBAErD,2DAA2D;gBAC3D,MAAM,aAAa,MAAM,KAAK,IAAI;gBAClC,MAAM,eAAe,KAAK,GAAG,CAAC,GAAG,aAAa;gBAC9C,MAAM,aAAa,KAAK,GAAG,CAAC,KAAK,MAAM,EAAE,aAAa,KAAK,CAAC,EAAE,CAAC,MAAM,GAAG;gBACxE,MAAM,UAAU,KAAK,SAAS,CAAC,cAAc;gBAE7C,QAAQ,GAAG,CAAC,CAAC,YAAY,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;gBAC3D,QAAQ,GAAG,CAAC,CAAC,gBAAgB,EAAE,QAAQ,GAAG,CAAC;gBAE3C,YAAY,IAAI,CAAC;oBACf,UAAU,QAAQ,QAAQ;oBAC1B,UAAU,QAAQ,QAAQ;oBAC1B,cAAc,KAAK,CAAC,EAAE;oBACtB,eAAe;oBACf,aAAa,QAAQ,WAAW;oBAChC,MAAM;gBACR;YACF;QACF;IACF;IAEA,OAAO;AACT;AAEO,eAAe,KAAK,OAAoB;IAC7C,QAAQ,GAAG,CAAC;IACZ,QAAQ,GAAG,CAAC;IACZ,QAAQ,GAAG,CAAC,gBAAgB,IAAI,OAAO,WAAW;IAClD,QAAQ,GAAG,CAAC,UAAU,QAAQ,GAAG;IACjC,QAAQ,GAAG,CAAC;IAEZ,IAAI;QACF,yBAAyB;QACzB,2DAA2D;QAC3D,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAA,6LAAI;QAE7B,IAAI,CAAC,QAAQ;YACX,QAAQ,KAAK,CAAC;YACd,QAAQ,KAAK,CAAC,kBAAkB,QAAQ,GAAG;YAC3C,QAAQ,KAAK,CAAC,sBAAsB;gBAClC,QAAQ,QAAQ,OAAO,CAAC,GAAG,CAAC,YAAY,sBAAsB,QAAQ,OAAO,CAAC,GAAG,CAAC,WAAW,SAAS,MAAM;gBAC5G,cAAc,QAAQ,OAAO,CAAC,GAAG,CAAC,eAAe,UAAU,GAAG,OAAO;YACvE;YACA,OAAO,oBACL,gBACA,qFACA;QAEJ;QAEA,QAAQ,GAAG,CAAC,yBAAyB;QACrC,QAAQ,GAAG,CAAC;QACZ,QAAQ,GAAG,CAAC,aAAa,QAAQ,MAAM;QACvC,QAAQ,GAAG,CAAC,mBAAmB,QAAQ,OAAO,CAAC,GAAG,CAAC;QAEnD,8DAA8D;QAC9D,IAAI;QACJ,IAAI;YACF,WAAW,MAAM,QAAQ,QAAQ;QACnC,EAAE,OAAO,YAAY;YACnB,QAAQ,KAAK,CAAC,gCAAgC;YAC9C,OAAO,oBACL,0BACA,iGACA;QAEJ;QACA,QAAQ,GAAG,CAAC;QACZ,MAAM,OAAO,SAAS,GAAG,CAAC;QAE1B,IAAI,CAAC,MAAM;YACT,QAAQ,KAAK,CAAC;YACd,OAAO,oBACL,oBACA,gDACA;QAEJ;QAEA,QAAQ,GAAG,CAAC,oBAAoB;YAC9B,MAAM,KAAK,IAAI;YACf,MAAM,KAAK,IAAI;YACf,MAAM,KAAK,IAAI;QACjB;QAEA,qBAAqB;QACrB,MAAM,WAAW,KAAK,IAAI,CAAC,WAAW;QACtC,MAAM,QAAQ,SAAS,QAAQ,CAAC,WAAW,KAAK,IAAI,KAAK;QACzD,MAAM,SAAS,SAAS,QAAQ,CAAC,YAAY,KAAK,IAAI,CAAC,QAAQ,CAAC;QAChE,MAAM,cAAc,SAAS,QAAQ,CAAC,WAAW,KAAK,IAAI,KAAK,gBAAgB,SAAS,GAAG,CAAC,mBAAmB;QAE/G,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,aAAa;YACrC,QAAQ,KAAK,CAAC,wBAAwB,UAAU,SAAS,KAAK,IAAI;YAClE,OAAO,oBACL,qBACA,CAAC,0DAA0D,EAAE,SAAS,EAAE,EAAE,KAAK,IAAI,CAAC,CAAC,CAAC,EACtF;QAEJ;QAEA,yBAAyB;QACzB,QAAQ,GAAG,CAAC;QACZ,IAAI;QACJ,IAAI;YACF,cAAc,MAAM,KAAK,WAAW;YACpC,QAAQ,GAAG,CAAC,sBAAsB,YAAY,UAAU;QAC1D,EAAE,OAAO,aAAa;YACpB,QAAQ,KAAK,CAAC,0BAA0B;YACxC,OAAO,oBACL,mBACA,6EACA;QAEJ;QAEA,IAAI;QACJ,IAAI;QACJ,IAAI;QACJ,IAAI;QAEJ,kFAAkF;QAClF,MAAM,aAAa,KAAK,GAAG,GAAG,QAAQ;QAEtC,mEAAmE;QACnE,IAAI;QAEJ,IAAI,OAAO;YACT,WAAW;YACX,QAAQ,GAAG,CAAC;YAEZ,IAAI;gBACF,6CAA6C;gBAC7C,SAAS,OAAO,IAAI,CAAC;gBAErB,oDAAoD;gBACpD,MAAM,EAAE,MAAM,mBAAmB,EAAE,SAAS,EAAE,GAAG,MAAM,IAAI,QAA+C,CAAC,SAAS;oBAClH,4DAA4D;oBAC5D,MAAM,YAAY,IAAK,0JAAS;oBAEhC,UAAU,EAAE,CAAC,uBAAuB,CAAC;wBACnC,QAAQ,KAAK,CAAC,oBAAoB,QAAQ,WAAW;wBACrD,OAAO,IAAI,MAAM,QAAQ,WAAW,IAAI;oBAC1C;oBAEA,UAAU,EAAE,CAAC,uBAAuB,CAAC;wBACnC,IAAI;4BACF,8BAA8B;4BAC9B,MAAM,WAAW,AAAC,UAAkB,iBAAiB;4BAErD,4CAA4C;4BAC5C,MAAM,YAAsB,EAAE;4BAC9B,IAAI,SAAS,SAAS,MAAM,OAAO,CAAC,QAAQ,KAAK,GAAG;gCAClD,QAAQ,GAAG,CAAC,CAAC,WAAW,EAAE,QAAQ,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC;gCACtD,QAAQ,KAAK,CAAC,OAAO,CAAC,CAAC,MAAW;oCAChC,IAAI,WAAW;oCACf,IAAI,KAAK,KAAK,IAAI,MAAM,OAAO,CAAC,KAAK,KAAK,GAAG;wCAC3C,WAAW,KAAK,KAAK,CAAC,GAAG,CAAC,CAAC;4CACzB,MAAM,cAAc,KAAK,CAAC,EAAE,CAAC,EAAE,EAAE,KAAK;4CACtC,IAAI;gDACF,qEAAqE;gDACrE,OAAO,mBAAmB;4CAC5B,EAAE,OAAO,aAAa;gDACpB,yDAAyD;gDACzD,QAAQ,IAAI,CAAC,CAAC,2BAA2B,EAAE,YAAY,kBAAkB,CAAC;gDAC1E,OAAO;4CACT;wCACF,GAAG,IAAI,CAAC;oCACV;oCACA,UAAU,IAAI,CAAC;oCACf,QAAQ,GAAG,CAAC,CAAC,OAAO,EAAE,QAAQ,EAAE,EAAE,EAAE,SAAS,MAAM,CAAC,MAAM,CAAC;gCAC7D;4BACF;4BAEA,QAAQ,GAAG,CAAC;4BACZ,QAAQ,GAAG,CAAC,uBAAuB,SAAS,SAAS,CAAC,GAAG;4BACzD,QAAQ;gCAAE,MAAM;gCAAU;4BAAU;wBACtC,EAAE,OAAO,KAAK;4BACZ,QAAQ,KAAK,CAAC,0BAA0B;4BACxC,OAAO;wBACT;oBACF;oBAEA,mBAAmB;oBACnB,UAAU,WAAW,CAAC;gBACxB;gBAEA,gBAAgB;gBAEhB,QAAQ,GAAG,CAAC,0BAA0B,cAAc,MAAM;gBAC1D,QAAQ,GAAG,CAAC,2BAA2B,cAAc,SAAS,CAAC,GAAG;gBAElE,kDAAkD;gBAClD,cAAc,cACX,KAAK,CAAC,QACN,MAAM,CAAC,CAAA,IAAK,EAAE,IAAI,IAClB,GAAG,CAAC,CAAA,IAAK,CAAC,GAAG,EAAE,EAAE,IAAI,GAAG,OAAO,CAAC,OAAO,QAAQ,IAAI,CAAC,EACpD,IAAI,CAAC;gBAER,sDAAsD;gBACtD,2CAA2C;gBAC3C,IAAA,+HAAQ,EAAC,YAAY,QAAQ,KAAK,IAAI;gBAEtC,6DAA6D;gBAC7D,MAAM,SAAS,OAAO,QAAQ,CAAC;gBAC/B,SAAS,CAAC,4BAA4B,EAAE,QAAQ;YAClD,EAAE,OAAO,UAAU;gBACjB,QAAQ,KAAK,CAAC,4BAA4B;gBAC1C,OAAO,oBACL,wBACA,oBAAoB,QAAQ,SAAS,OAAO,GAAG,uFAC/C;YAEJ;QAEF,OAAO,IAAI,aAAa;YACtB,WAAW,QAAQ,sDAAsD;YACzE,QAAQ,GAAG,CAAC;YAEZ,IAAI;gBACF,2BAA2B;gBAC3B,MAAM,cAAc,IAAI,YAAY;gBACpC,gBAAgB,YAAY,MAAM,CAAC;gBACnC,QAAQ,GAAG,CAAC,0BAA0B,cAAc,MAAM;gBAC1D,QAAQ,GAAG,CAAC,2BAA2B,cAAc,SAAS,CAAC,GAAG;gBAElE,wCAAwC;gBACxC,cAAc,cACX,KAAK,CAAC,MACN,MAAM,CAAC,CAAA,IAAK,EAAE,IAAI,IAClB,GAAG,CAAC,CAAA,IAAK,CAAC,GAAG,EAAE,EAAE,IAAI,GAAG,IAAI,CAAC,EAC7B,IAAI,CAAC;gBACR,QAAQ,GAAG,CAAC,wBAAwB,YAAY,MAAM;YACxD,EAAE,OAAO,WAAW;gBAClB,QAAQ,KAAK,CAAC,6BAA6B;gBAC3C,OAAO,oBACL,yBACA,qBAAqB,QAAQ,UAAU,OAAO,GAAG,gCACjD;YAEJ;QAEF,OAAO;YACL,WAAW;YACX,QAAQ,GAAG,CAAC;YAEZ,IAAI;gBACF,4CAA4C;gBAC5C,SAAS,OAAO,IAAI,CAAC;gBACrB,QAAQ,GAAG,CAAC,gBAAgB,OAAO,MAAM;gBAEzC,QAAQ,GAAG,CAAC;gBACZ,MAAM,SAAS,MAAM,oJAAO,CAAC,cAAc,CAAC;oBAAE;gBAAO;gBACrD,gBAAgB,OAAO,KAAK;gBAC5B,QAAQ,GAAG,CAAC,0BAA0B,cAAc,MAAM;gBAE1D,kCAAkC;gBAClC,QAAQ,GAAG,CAAC;gBACZ,MAAM,aAAa,MAAM,oJAAO,CAAC,aAAa,CAAC;oBAAE;gBAAO;gBACxD,cAAc,WAAW,KAAK;gBAC9B,QAAQ,GAAG,CAAC,wBAAwB,YAAY,MAAM;YACxD,EAAE,OAAO,WAAW;gBAClB,QAAQ,KAAK,CAAC,6BAA6B;gBAC3C,OAAO,oBACL,yBACA,qBAAqB,QAAQ,UAAU,OAAO,GAAG,wFACjD;YAEJ;QACF;QAEA,uCAAuC;QACvC,QAAQ,GAAG,CAAC;QACZ,MAAM,cAAc,uBAAuB;QAC3C,QAAQ,GAAG,CAAC,CAAC,QAAQ,EAAE,YAAY,MAAM,CAAC,uBAAuB,CAAC;QAElE,IAAI,YAAY,MAAM,GAAG,GAAG;YAC1B,QAAQ,GAAG,CAAC,sBAAsB,WAAW,CAAC,EAAE;QAClD,OAAO;YACL,QAAQ,GAAG,CAAC,kDAAkD,cAAc,SAAS,CAAC,GAAG;QAC3F;QAEA,4BAA4B;QAC5B,QAAQ,GAAG,CAAC;QACZ,IAAI;QACJ,IAAI;YACF,uEAAuE;YACvE,sEAAsE;YACtE,MAAM,aAAa,CAAC,QAAQ,EAAE,YAAY;YAE1C,gBAAgB,MAAM,IAAA,8IAAoB,EACxC,QACA,KAAK,IAAI,EACT,UACA;YAGF,QAAQ,GAAG,CAAC,iCAAiC,cAAc,EAAE;YAE7D,+BAA+B;YAC/B,IAAI,YAAY,MAAM,GAAG,GAAG;gBAC1B,QAAQ,GAAG,CAAC;gBACZ,MAAM,gBAAgB,YAAY,GAAG,CAAC,CAAA,IAAK,CAAC;wBAC1C,UAAU,EAAE,QAAQ;wBACpB,OAAO,EAAE,WAAW;wBACpB,UAAU,EAAE,QAAQ;wBACpB,YAAY;wBACZ,UAAU;wBACV,cAAc,EAAE,aAAa;oBAC/B,CAAC;gBAED,MAAM,IAAA,2IAAiB,EAAC,cAAc,EAAE,EAAE;gBAC1C,QAAQ,GAAG,CAAC,CAAC,QAAQ,EAAE,YAAY,MAAM,CAAC,wBAAwB,CAAC;YACrE;QACF,EAAE,OAAO,SAAS;YAChB,QAAQ,KAAK,CAAC,qBAAqB;QACnC,qDAAqD;QACrD,2DAA2D;QAC7D;QAEA,iEAAiE;QACjE,MAAM,kBAAkB;QAExB,MAAM,kBAAkB;YACtB,SAAS;YACT,YAAY,eAAe,MAAM;YACjC,UAAU,KAAK,IAAI;YACnB;YACA;YACA;YACA;YACA;YACA,MAAM;YACN,SAAS,CAAC,yBAAyB,EAAE,YAAY,MAAM,CAAC,aAAa,CAAC;QACxE;QAEA,QAAQ,GAAG,CAAC;QACZ,QAAQ,GAAG,CAAC,kBAAkB,gBAAgB,UAAU;QACxD,QAAQ,GAAG,CAAC,gBAAgB,gBAAgB,QAAQ;QACpD,QAAQ,GAAG,CAAC,wBAAwB,gBAAgB,WAAW,CAAC,MAAM;QAEtE,OAAO,gJAAY,CAAC,IAAI,CAAC;IAC3B,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC;QACd,QAAQ,KAAK,CAAC;QACd,QAAQ,KAAK,CAAC;QACd,QAAQ,KAAK,CAAC,eAAe,OAAO,aAAa,QAAQ,OAAO;QAChE,QAAQ,KAAK,CAAC,kBAAkB,iBAAiB,QAAQ,MAAM,OAAO,GAAG,OAAO;QAChF,QAAQ,KAAK,CAAC,gBAAgB,iBAAiB,QAAQ,MAAM,KAAK,GAAG;QACrE,QAAQ,KAAK,CAAC,sBAAsB,KAAK,SAAS,CAAC,OAAO,OAAO,mBAAmB,CAAC,QAAQ;QAE7F,MAAM,eAAe,iBAAiB,QAAQ,MAAM,OAAO,GAAG,OAAO;QACrE,MAAM,gBAAgB,oBACpB,8BACA,gBAAgB,yDAChB;QAGF,qDAAqD;QACrD,QAAQ,GAAG,CAAC,4CAA4C,cAAc,MAAM;QAE5E,OAAO;IACT;AACF","debugId":null}}]
}